{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "149f8b57-6c30-4b9d-9829-eed11db71f0a",
   "metadata": {},
   "source": [
    "Reading from HYDAT for a test case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "871552fd-6088-4459-baf5-0b3cedd44d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Change to your own HYDAT \n",
    "obs_path = '/Users/kasrakeshavarz/Downloads/Hydat.sqlite3'\n",
    "\n",
    "# read observed data\n",
    "conn = sqlite3.connect(obs_path) # locate your HYDAT sqlite database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1534ff2-d56a-4dd1-b2f2-af087ecb23b4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_the_daily_dataframe(\n",
    "    df: pd.DataFrame,\n",
    "    regex_str: str,\n",
    "    col: str,\n",
    "    *args,\n",
    "    **kwargs,\n",
    ") -> pd.DataFrame:\n",
    "    \n",
    "    # filter and trim columns\n",
    "    df = df.filter(regex=regex_str, axis=1) # extract the columns\n",
    "    df.columns = df.columns.str.replace(r'\\D', '', regex=True) # remove non-digits\n",
    "    df = df.stack(future_stack=True) # stack without dropping\n",
    "    df.index.names = ['STATION_NUMBER', 'YEAR', 'MONTH', 'DAY'] # assign index names\n",
    "    df = df.reset_index() # reset index to add another level\n",
    "    df['DATE'] = pd.to_datetime(df[['YEAR', 'MONTH', 'DAY']].astype(str).agg('-'.join, axis=1), errors='coerce') # define date column\n",
    "    df.drop(columns=['YEAR', 'MONTH', 'DAY'], inplace=True) # drop unnecessary columns\n",
    "    df.dropna(subset=['DATE'], inplace=True) # remove invalid dates\n",
    "    df.set_index(keys=['STATION_NUMBER', 'DATE'], drop=True, inplace=True) # set index levels\n",
    "    df.columns = [col] # assing column name\n",
    "    \n",
    "    # pivot data to look nice\n",
    "    df = df.unstack(level='STATION_NUMBER')\n",
    "    df = df.reorder_levels(order=[1,0], axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extract_station_daily_flow(\n",
    "    station: str,\n",
    "    connection: sqlite3.Connection,\n",
    "    start_date: str = '1850-01-01',\n",
    "    end_date: str = str(datetime.datetime.now().date()),\n",
    "    *args,\n",
    "    **kwargs,\n",
    ") -> pd.DataFrame:\n",
    "    \n",
    "    '''\n",
    "    This function simply extracts data from the HYDAT sqlite3 database\n",
    "    '''\n",
    "    \n",
    "    # read station data\n",
    "    df = pd.read_sql_query(f\"SELECT * FROM DLY_FLOWS WHERE STATION_NUMBER LIKE '%{station}%'\", connection)\n",
    "    \n",
    "    # set index\n",
    "    df.set_index(keys=['STATION_NUMBER', 'YEAR', 'MONTH'], drop=True, inplace=True)\n",
    "    \n",
    "    # get the FLOW and FLAG\n",
    "    df_flow = get_the_daily_dataframe(df, r'^FLOW\\d', 'FLOW')\n",
    "    df_flag = get_the_daily_dataframe(df, r'^FLOW_.', 'FLAG')\n",
    "    \n",
    "    df = pd.concat([df_flow, df_flag], \n",
    "                   axis=1)\n",
    "    df.sort_index(axis=0, inplace=True)\n",
    "    df.sort_index(axis=1, level=0, ascending=False, inplace=True)\n",
    "    \n",
    "    df = df.loc[start_date:end_date, :]\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def extract_station_coords(\n",
    "    station: str,\n",
    "    connection: sqlite3.Connection,\n",
    ") -> dict:\n",
    "    '''\n",
    "    returns `latitude` and `longitude` values for `station`\n",
    "    '''\n",
    "    \n",
    "    # read the specs\n",
    "    df = pd.read_sql_query(f\"SELECT * FROM STATIONS WHERE STATION_NUMBER LIKE '%{station}%'\", conn)\n",
    "    \n",
    "    # rename the columns to their lowercase equivalent\n",
    "    df.rename(\n",
    "        columns={\n",
    "            'LATITUDE': 'latitude',\n",
    "            'LONGITUDE': 'longitude',\n",
    "        },\n",
    "        inplace=True,\n",
    "    )\n",
    "    \n",
    "    # making a dictionary out of the values\n",
    "    vals_dict = df.loc[:, ['latitude', 'longitude']].to_dict(orient='list')\n",
    "    \n",
    "    # return the values in form of a dictionary\n",
    "    vals_dict = {k:v[0] for k,v in vals_dict.items()}\n",
    "    \n",
    "    return vals_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b24d8c2b-6aeb-45ba-a8e5-0c96131f6823",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = extract_station_daily_flow('05BB001', connection=conn, end_date=\"2026-12-31\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f33b9ed-346c-41b8-937f-c037163e5634",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = extract_station_coords(station='05BB001', connection=conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe44e30-9313-45c0-b006-e218d25789c5",
   "metadata": {},
   "source": [
    "Check for missing time-steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d66c7355-2f58-4592-9040-79e0432ad336",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = '1D'  # set your expected step\n",
    "df2 = df.asfreq(freq)  # inserts missing timestamps with NaNs\n",
    "missing_timestamps = df2.index[df2.isna().any(axis=1)]\n",
    "has_missing = len(missing_timestamps) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56b45d20-9b02-42f3-8080-7ccd5ddfdf10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "has_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be5f5aa-db79-4cc0-8543-3d17562d9faf",
   "metadata": {},
   "source": [
    "Since it is a real case, we will proceed with it as is. First, assuring missing time-stamps are included:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b344a387-4c4c-48aa-bb1f-5f934d515355",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = '1D'\n",
    "full_index = pd.date_range(df.index.min(), df.index.max(), freq=freq, tz=df.index.tz)\n",
    "df_full = df.reindex(full_index)  # missing rows → NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc66cf7b-17da-4c1c-8e0a-a3d10ef7712d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>STATION_NUMBER</th>\n",
       "      <th colspan=\"2\" halign=\"left\">05BB001</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>FLOW</th>\n",
       "      <th>FLAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1909-05-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1909-05-02</th>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1909-05-03</th>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1909-05-04</th>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1909-05-05</th>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-27</th>\n",
       "      <td>13.1</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-28</th>\n",
       "      <td>11.9</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-29</th>\n",
       "      <td>12.9</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-30</th>\n",
       "      <td>12.9</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-31</th>\n",
       "      <td>12.1</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42249 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "STATION_NUMBER 05BB001      \n",
       "                  FLOW  FLAG\n",
       "1909-05-01         NaN  None\n",
       "1909-05-02         NaN  None\n",
       "1909-05-03         NaN  None\n",
       "1909-05-04         NaN  None\n",
       "1909-05-05         NaN  None\n",
       "...                ...   ...\n",
       "2024-12-27        13.1     B\n",
       "2024-12-28        11.9     B\n",
       "2024-12-29        12.9     B\n",
       "2024-12-30        12.9     B\n",
       "2024-12-31        12.1     B\n",
       "\n",
       "[42249 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27127b7f-0c0f-42b9-9b5d-eadd21a6c304",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1909-05-01     NaN\n",
       "1909-05-02     NaN\n",
       "1909-05-03     NaN\n",
       "1909-05-04     NaN\n",
       "1909-05-05     NaN\n",
       "              ... \n",
       "2024-12-27    13.1\n",
       "2024-12-28    11.9\n",
       "2024-12-29    12.9\n",
       "2024-12-30    12.9\n",
       "2024-12-31    12.1\n",
       "Freq: D, Name: FLOW, Length: 42249, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full['05BB001']['FLOW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a7fa3c0-a930-46de-8f0e-8f2c57af9363",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = {\n",
    "    'type': 'QO',\n",
    "    'location': coords,\n",
    "    'timeseries': df_full['05BB001']['FLOW'],\n",
    "    'units': 'm3/s',\n",
    "    'freq': '1D',\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meshflow",
   "language": "python",
   "name": "meshflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
